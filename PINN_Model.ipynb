{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNLNI8G0oFqdRLm5gYzLVS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nourallaah/FitzHugh-Nagumo-PINN-Simulation/blob/main/PINN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**This notebook simulated the solutions of the reaction-diffusion system based on the Fitzhugh-Nagumo PDE model by Using Physics-informed neural networks (PINN)**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "There will also be results for the predefined case 4.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Detailed explanation of all the functions are in the Comparison notebook.**"
      ],
      "metadata": {
        "id": "Qd-EvzutIrHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "EhCZHsRwJ_S7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "`numpy`: For numerical operations and creating grids.\n",
        "\n",
        "`matplotlib.pyplot`: For plotting heatmaps of the solution.\n",
        "\n",
        "`torch` and `torch.nn`: PyTorch library for building and training neural networks.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "F5oCPfAHKJ7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D, a = 1.0, 0.3  # Physical parameters of the FitzHugh-Nagumo (FHN) equation\n",
        "xmin, xmax = -5, 5  # Spatial domain boundaries\n",
        "N_x = 200  # Number of spatial points for evaluation and plotting\n",
        "t_min, t_max = 0.0, 2  # Time domain boundaries\n",
        "N_t = 100  # Number of time points for heatmap resolution\n",
        "ncase = 4  # Boundary condition case selector"
      ],
      "metadata": {
        "id": "5ciGVGqTKNZk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "- These parameters define the PDE coefficients, spatial and temporal domain, and resolution.\n",
        "\n",
        "- We are evaluating the model on a different spatial and temporal domain than in the comparison model to be able to see a difference between the cases in the heatmap.\n",
        "\n",
        "- `ncase` allows switching between different boundary conditions.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BEkrW3EyKUsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_exp(z):\n",
        "    return np.exp(np.clip(z, -700, 700))\n",
        "def analytical_solution(x, t, D=1.0, a=0.3):\n",
        "    return 1 / (1 + safe_exp(x / np.sqrt(2 * D) + (a - 0.5) * t))\n",
        "def analytical_solution_derivative(x, t, D=1.0, a=0.3):\n",
        "    exp_term = safe_exp(x / np.sqrt(2 * D) + (a - 0.5) * t)\n",
        "    denom = (1 + exp_term) ** 2\n",
        "    return -exp_term / (np.sqrt(2 * D) * denom)"
      ],
      "metadata": {
        "id": "UoDuKaUNKfzx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`safe_exp` : Prevents overflow in exponential by clipping input values\n",
        "\n",
        "`analytical_solution` : Provides exact solution values at boundaries and initial time to enforce conditions in training.\n",
        "\n",
        "`analytical_solution_derivative` : Computes the spatial derivative of the analytical solution at position `x` and time `t`.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tslhzoVXKp3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FHN_PINN(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super(FHN_PINN, self).__init__()\n",
        "        modules = []\n",
        "        for i in range(len(layers) - 1):\n",
        "            modules.append(nn.Linear(layers[i], layers[i + 1]))\n",
        "            if i < len(layers) - 2:\n",
        "                modules.append(nn.Tanh())  # Activation function\n",
        "        self.net = nn.Sequential(*modules)\n",
        "\n",
        "        # Xavier initialization for weights and zero bias initialization\n",
        "        for m in self.net:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # Forward pass: concatenate spatial and temporal inputs\n",
        "        return self.net(torch.cat([x, t], dim=1))"
      ],
      "metadata": {
        "id": "4oZ93sjMK_C0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The network takes spatial coordinate `x` and time `t` as inputs.\n",
        "\n",
        "- Uses `Tanh` activations for smoothness.\n",
        "\n",
        "- Xavier initialization helps with stable training.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LfP1H-58LCV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fhn_pde_loss(model, x, t, D, a):\n",
        "    x = x.clone().detach().float().requires_grad_(True)\n",
        "    t = t.clone().detach().float().requires_grad_(True)\n",
        "    uv = model(x, t)\n",
        "    u = uv[:, 0:1]\n",
        "\n",
        "    # Compute gradients for PDE residual\n",
        "    u_t = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True)[0]\n",
        "    u_x = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]\n",
        "    u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u), create_graph=True)[0]\n",
        "\n",
        "    # PDE residual for FitzHugh-Nagumo equation\n",
        "    f_u = u_t - D * u_xx - (u - u ** 3 / 3)\n",
        "\n",
        "    return (f_u ** 2).mean()"
      ],
      "metadata": {
        "id": "G22uVjzLLNMq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This loss enforces the PDE by penalizing deviations of the network output from satisfying the equation.\n",
        "\n",
        "- Uses automatic differentiation to compute derivatives w.r.t inputs.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rQDtIqinLOjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initial_condition_loss(model, x0, t0, u0):\n",
        "    uv_pred = model(x0, t0)\n",
        "    return ((uv_pred[:, 0:1] - u0) ** 2).mean()"
      ],
      "metadata": {
        "id": "R8kZCuhBLV5S"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Penalizes difference between predicted and known initial condition values.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GiQb5JZULW-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def boundary_condition_loss(model, xb, tb, ncase):\n",
        "    xb = xb.clone().detach().float().requires_grad_(True)\n",
        "    tb = tb.clone().detach().float()\n",
        "    uv_pred = model(xb, tb)\n",
        "    u = uv_pred[:, 0:1]\n",
        "\n",
        "    if ncase == 1:\n",
        "        # Case 1: Use analytical solution at boundaries\n",
        "        u_left = torch.tensor(analytical_solution(xmin, tb[:len(tb)//2].numpy()), dtype=torch.float32).reshape(-1, 1)\n",
        "        u_right = torch.tensor(analytical_solution(xmax, tb[len(tb)//2:].numpy()), dtype=torch.float32).reshape(-1, 1)\n",
        "        u_target = torch.cat([u_left, u_right], dim=0)\n",
        "        return ((u - u_target) ** 2).mean()\n",
        "    elif ncase == 2:\n",
        "        # Case 2: Fixed boundary values (example)\n",
        "        left_vals = torch.ones_like(tb[:len(tb)//2])\n",
        "        right_vals = torch.zeros_like(tb[len(tb)//2:])\n",
        "        u_target = torch.cat([left_vals, right_vals]).reshape(-1, 1)\n",
        "        return ((u - u_target) ** 2).mean()\n",
        "    elif ncase == 3:\n",
        "        #case 3 : Fixed Dirichlet BC\n",
        "        u = uv_pred[:, 0:1]\n",
        "        u_x = torch.autograd.grad(u, xb, torch.ones_like(u), create_graph=True)[0]\n",
        "        u_x_left = u_x[:N_x]\n",
        "        u_x_right = u_x[N_x:]\n",
        "        tb_left_np = tb[:N_x].numpy()\n",
        "        tb_right_np = tb[N_x:].numpy()\n",
        "        ux_left_np = analytical_solution_derivative(xmin, tb_left_np, D, a)\n",
        "        ux_right_np = analytical_solution_derivative(xmax, tb_right_np, D, a)\n",
        "        ux_left = torch.tensor(ux_left_np, dtype=torch.float32).reshape(-1, 1)\n",
        "        ux_right = torch.tensor(ux_right_np, dtype=torch.float32).reshape(-1, 1)\n",
        "        return ((u_x_left - ux_left) ** 2).mean() + ((u_x_right - ux_right) ** 2).mean()\n",
        "    elif ncase == 4:\n",
        "        #case 4 : Neumann BC\n",
        "        u = uv_pred[:, 0:1]\n",
        "        u_x = torch.autograd.grad(u, xb, torch.ones_like(u), create_graph=True)[0]\n",
        "        return (u_x ** 2).mean()\n",
        "    elif ncase == 5:\n",
        "        # case 5: No boundary condition loss\n",
        "        return torch.tensor(0.0, device=uv_pred.device)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported ncase {ncase}\")"
      ],
      "metadata": {
        "id": "p6iHpxfhLZq3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function computes the boundary condition loss for the PINN model, enforcing different types of boundary conditions depending on `ncase` having these different types:\n",
        "- case 1: **Dirichlet boundary condition**, where the solution is fixed to known values at the edges.\n",
        "- case 2: **Fixed Dirichlet BC**, where the left boundary is set to 1.0 and the right boundary to 0.0.\n",
        "- case 3: applying the **Neumann boundary conditions** specifying the derivative of u at the boundaries.\n",
        "- case 4: **Neumann BC with Zero Gradient** Sets the boundary values equal to their immediate neighbors inside the domain.\n",
        "- case 5: **Free of boundary conditions**\n",
        "\n"
      ],
      "metadata": {
        "id": "ZC8gXJmINNt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_pinn(t_min, t_max, ncase, epochs=4000):\n",
        "    layers = [2, 100, 100, 100, 2]  # Input: (x,t), Output: (u,v)\n",
        "    model = FHN_PINN(layers)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Initial condition points\n",
        "    x_tensor = torch.tensor(np.linspace(xmin, xmax, N_x), dtype=torch.float32).reshape(-1, 1)\n",
        "    u0_np = analytical_solution(x_tensor.numpy().flatten(), t_min)\n",
        "    u0 = torch.tensor(u0_np, dtype=torch.float32).reshape(-1, 1)\n",
        "    t0 = torch.full_like(x_tensor, t_min)\n",
        "\n",
        "    # Collocation points inside domain for PDE residual\n",
        "    N_colloc = 5000\n",
        "    x_colloc = torch.tensor(np.random.uniform(xmin, xmax, N_colloc), dtype=torch.float32).reshape(-1, 1)\n",
        "    t_colloc = torch.tensor(np.random.uniform(t_min, t_max, N_colloc), dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Boundary points for enforcing BC\n",
        "    N_b = 200\n",
        "    xb = torch.cat([\n",
        "        torch.full((N_b, 1), xmin, dtype=torch.float32),\n",
        "        torch.full((N_b, 1), xmax, dtype=torch.float32)\n",
        "    ], dim=0)\n",
        "    tb = torch.tensor(np.random.uniform(t_min, t_max, 2*N_b), dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        loss_pde = fhn_pde_loss(model, x_colloc, t_colloc, D, a)\n",
        "        loss_ic = initial_condition_loss(model, x_tensor, t0, u0)\n",
        "        loss_bc = boundary_condition_loss(model, xb, tb, ncase)\n",
        "\n",
        "        # Weighted sum of losses\n",
        "        loss = 100.0 * loss_pde + 30.0 * loss_ic + 50.0 * loss_bc\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 500 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {loss.item():.4e}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "epfuJ_p1NoKY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "This function trains a Physics-Informed Neural Network (PINN) to approximate the solution of a PDE on a time interval `[t_start, t_end]` with specified boundary conditions (`ncase`).\n",
        "\n",
        "- It defines a fully connected neural network (`FHN_PINN`) with 3 hidden layers of 100 neurons each.\n",
        "- Creates tensors for spatial points, initial conditions at `t_start`, and collocation points sampled randomly in space-time for enforcing the PDE.\n",
        "- Defines boundary points at the spatial domain edges at time `t_end`.\n",
        "- In each training epoch, it computes a weighted sum of three losses:\n",
        "  - PDE residual loss at collocation points,\n",
        "  - Initial condition loss at `t_start`,\n",
        "  - Boundary condition loss at boundaries and `t_end`.\n",
        "- They are weighted that way after trying to find the best balanced ratio to produce accurate results.  \n",
        "- Uses Adam optimizer to minimize this composite loss.\n",
        "- Prints loss every 500 epochs for a total of 4000 epochs.\n",
        "- Returns the trained model after the specified number of epochs.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hB2uCxZfP17B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Train the PINN model\n",
        "    print(\"Training PINN...\")\n",
        "    pinn_model = train_pinn(t_min, t_max, ncase)\n",
        "\n",
        "    # Create grid for visualization\n",
        "    t_grid = np.linspace(t_min, t_max, N_t)\n",
        "    X, T = np.meshgrid(np.linspace(xmin, xmax, N_x), t_grid, indexing='ij')\n",
        "\n",
        "    # Predict solution on the grid\n",
        "    U_pred = np.zeros((N_x, N_t))\n",
        "    for j, t_val in enumerate(t_grid):\n",
        "        x_tensor = torch.tensor(np.linspace(xmin, xmax, N_x), dtype=torch.float32).reshape(-1, 1)\n",
        "        t_tensor = torch.full_like(x_tensor, t_val)\n",
        "        with torch.no_grad():\n",
        "            U_pred[:, j] = pinn_model(x_tensor, t_tensor)[:, 0].numpy()\n",
        "\n",
        "    # Plot heatmap of u(x,t)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.pcolormesh(T, X, U_pred, shading='auto', cmap='viridis')\n",
        "    plt.colorbar(label='u(x,t)')\n",
        "    plt.xlabel('Time (t)')\n",
        "    plt.ylabel('Space (x)')\n",
        "    plt.title(f'FHN Equation Solution (PINN, Case {ncase})')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc-rjrtsP5BC",
        "outputId": "ed5947e7-4feb-45a3-ac79-955b32ec6a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PINN...\n",
            "Epoch 0: Loss = 2.0780e+01\n",
            "Epoch 500: Loss = 6.6864e-01\n",
            "Epoch 1000: Loss = 1.3532e-01\n",
            "Epoch 1500: Loss = 7.6801e-02\n",
            "Epoch 2000: Loss = 5.6128e-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "After training, evaluates the model on a mesh grid of space and time.\n",
        "\n",
        "Uses pcolormesh to create a heatmap showing the solution evolution.\n",
        "\n",
        "Labels axes and adds a colorbar for clarity.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oteMF2pnP8zG"
      }
    }
  ]
}